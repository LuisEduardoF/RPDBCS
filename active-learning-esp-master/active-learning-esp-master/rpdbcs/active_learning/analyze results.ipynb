{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "\n",
    "plt.rcParams['figure.dpi']=256\n",
    "plt.rcParams['figure.figsize']=(13,6)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(200,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fpath = 'results/data_classified_v6/25-11-2020.csv'\n",
    "# fpath = 'results/data_classified_v6/18-11-2020.csv'\n",
    "#fpath = 'results/data_classified_v6/tmp.csv'\n",
    "\n",
    "\n",
    "def extract_query_strategy(row):\n",
    "    name=row['classifier name']\n",
    "    if('alldata' in name):\n",
    "        return 'alldata'\n",
    "    return name.split('[')[-1].replace(']','').strip()\n",
    "\n",
    "def base_classifier(row):\n",
    "    names = ['knn','QDA','DT','RF','NB']\n",
    "    for name in names:\n",
    "        if(name in row['classifier name']):\n",
    "            return name.strip()\n",
    "    return None\n",
    "\n",
    "def space_col(row):\n",
    "    name = row['classifier name']\n",
    "    if('triplet' in name):\n",
    "        return 'triplet'\n",
    "    if('convnet' in name):\n",
    "        return 'convnet'\n",
    "    return 'hand-crafted'\n",
    "\n",
    "CACHED_DF=(\"\",None)\n",
    "def loadDataResults(fpath):\n",
    "    global CACHED_DF\n",
    "    if(fpath==CACHED_DF[0]):\n",
    "        return CACHED_DF[1]\n",
    "    df = pd.read_csv(fpath)\n",
    "\n",
    "    df['query strategy'] = df.apply(extract_query_strategy, axis=1)\n",
    "    df['base_classifier']=df.apply(base_classifier, axis=1)\n",
    "    df['space'] = df.apply(space_col, axis=1)\n",
    "    df['classifier name'] = df['classifier name'].str.split('[').str[0].str.strip()\n",
    "    df['classifier name']=df['classifier name'].str.replace('\\(alldata\\)','').str.strip()\n",
    "    #if(fpath=='results/data_classified_v6/25-11-2020.csv'):\n",
    "    df['train size']+=8\n",
    "    CACHED_DF=(fpath,df)\n",
    "    return df\n",
    "\n",
    "#df=loadDataResults(fpath)\n",
    "#df\n",
    "#df[(df['value']>=0.9) & (df['metric name']=='f1_macro') & (df['train size']>=950)]\n",
    "#df[df['classifier name'].str.split(' ').str[0]=='convnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67e7b6b55394d1983a33c33367e87be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Methods:', layout=Layout(height='120px', width='30%'), optio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def interact_results(methods, dataset_path, query_strategy='entropy', metric='f1_macro'):\n",
    "    df=loadDataResults(dataset_path)\n",
    "    mask = df['metric name']==metric\n",
    "    #mask &= ~(df['query strategy']=='alldata')\n",
    "    #mask &= ~df['classifier name'].str.contains('QDA')\n",
    "    mask &= df['classifier name'].str.strip().isin(methods)\n",
    "    mask2 = mask & df['query strategy'].isin(query_strategy)#,'random'])\n",
    "    #mask &= (df['base_classifier']==base_classifier) | (df['space']=='hand-crafted')\n",
    "    \n",
    "    df_alldata=df[mask]\n",
    "    df_alldata=df_alldata[df_alldata['query strategy']=='alldata']\n",
    "    df3=df[mask2]\n",
    "    \n",
    "    n_cname = len(df3['classifier name'].unique())\n",
    "    n_space = len(df3['space'].unique())\n",
    "    n_qstrat = len(df3['query strategy'].unique())\n",
    "    \n",
    "    max_train_size=df3['train size'].max()\n",
    "    min_train_size=df3['train size'].min()\n",
    "    \n",
    "    style=None\n",
    "    if(n_cname>1):\n",
    "        hue='classifier name'\n",
    "        style='query strategy'\n",
    "    else:\n",
    "        hue='query strategy'\n",
    "    if(n_space>1):\n",
    "        style='space'\n",
    "    style = 'query strategy'\n",
    "            \n",
    "    for v in df_alldata['value']:\n",
    "        plt.plot([min_train_size,max_train_size],[v,v], linestyle=':', linewidth=3)\n",
    "    sns.lineplot(data=df3,x='train size',y='value', hue=hue, marker='o', style=style);\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(df3['train size'].unique())\n",
    "    plt.ylim([0.0,1.0]);\n",
    "\n",
    "\n",
    "results_dir='results/data_classified_v6'\n",
    "widget_dataset = widgets.Dropdown(\n",
    "    #options=[results_dir+'/'+f for f in os.listdir(results_dir) if 'tmp' not in f],\n",
    "    options=[results_dir+'/'+f for f in os.listdir(results_dir)],\n",
    "    value=results_dir+'/'+'25-11-2020.csv',\n",
    "    description='Results file:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='30%')\n",
    ")\n",
    "    \n",
    "    \n",
    "widget_methods = widgets.SelectMultiple(\n",
    "    value=[],\n",
    "    description='Methods:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='30%', height='120px')\n",
    ")\n",
    "\n",
    "widget_querystrat = widgets.SelectMultiple(\n",
    "    value=[],\n",
    "    description='Query Strategy:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_widgets(*args):\n",
    "    df=loadDataResults(widget_dataset.value)\n",
    "    widget_methods.options = df['classifier name'].str.strip().unique()\n",
    "    widget_querystrat.options=df['query strategy'].unique()\n",
    "\n",
    "widget_dataset.observe(update_widgets, 'value')\n",
    "update_widgets()\n",
    "\n",
    "interact(interact_results,\n",
    "         methods=widget_methods,\n",
    "         dataset_path=widget_dataset,\n",
    "         query_strategy=widget_querystrat,\n",
    "         metric=df['metric name'].unique());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\PP}{\\mathbf{P}}$\n",
    "$\\newcommand{\\xx}{\\mathbf{x}}$\n",
    "\n",
    "$p_i=\\PP(y_i=1|\\xx)$\n",
    "\n",
    "-  Três query functions: \n",
    "   -  Top Margin: $1-\\max_i p_i$\n",
    "   -  1-2 Margin: $\\max_i(p_i) - \\max^{(2)}_i (p_i)$\n",
    "   -  Entropy:  $-\\sum_i p_i log(p_i)$\n",
    "   -  Random.\n",
    "\n",
    "# 19/11/2020\n",
    "### Configuração experimental\n",
    "\n",
    "-  5600 exemplos (v6)\n",
    "-  Base de treino inicial (Estratificada): 100\n",
    "-  Query size: 50\n",
    "-  Budget: +900\n",
    "-  Exemplos de teste: 1835\n",
    "-  Hand-crafted space: 8 Features do ICTAI2016.\n",
    "\n",
    "### Observações\n",
    "\n",
    "-  Os classificadores no hand-crafted space já começam alto, em especial o DT e RF. \n",
    "-  Triplet-net com knn ou RF foram bons.\n",
    "-  O triplet-net com DT ficou bom no final.\n",
    "-  A convergência é bem rápida para os métodos no hand-crafted space. \n",
    "-  Parece três deles convergem pra um mesmo ponto, mas não são o mesmo ponto.\n",
    "\n",
    "# 26/11/2020\n",
    "### Configuração experimental\n",
    "\n",
    "-  5616 exemplos (v6)\n",
    "-  Base de treino inicial: 40 (5 de cada defeito e 20 normais)\n",
    "-  Query size: 15\n",
    "-  Budget: +420\n",
    "-  Exemplos de teste: 1855\n",
    "-  Hand-crafted space: 8 Features do ICTAI2016.\n",
    "\n",
    "### Observações\n",
    "-  Os métodos por triplet loss conseguiram alcançar um desempenho bem mais rápido, comparado ao experimentos de 19/11/2020.\n",
    "-  MC dropout é muito bom! (ele usa uma média de 20 predições)\n",
    "-  Qualquer query strategy é melhor do que o random em quase todos os casos.\n",
    "-  O triplenet é horrivel no inicio pq ele prediz consegue precisão ou recall 0 em certas classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8438a048811b48d68fb92585e38f2e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Methods:', options=('tripletnet_mcdropout', 'ensemble_triple…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.special import logit\n",
    "\n",
    "df['value_logit'] = logit(df['value'])\n",
    "\n",
    "def interact_results(method, metric='f1_macro', base_classifier='ALL'):\n",
    "    mask = df['metric name']==(metric)\n",
    "    mask &= ~df['classifier name'].str.contains('alldata')\n",
    "    mask &= df['classifier name'].str.split(' ').str[0].isin(method)\n",
    "    #mask &= ~df['base_classifier'].str.contains('QDA')\n",
    "    \n",
    "    if(base_classifier!='ALL'):\n",
    "        mask &= df['base_classifier']==base_classifier\n",
    "    sns.lineplot(data=df[mask],x='train size',y='value', hue='query strategy', marker='o', style='base_classifier');\n",
    "    #plt.xticks(df[mask]['train size'])\n",
    "    plt.ylabel('Macro F-measure')\n",
    "    plt.ylim([0.0,1.0]);\n",
    "\n",
    "    \n",
    "widget_methods = widgets.SelectMultiple(\n",
    "    options=df['classifier name'].str.split(' ').str[0].unique(),\n",
    "    value=[],\n",
    "    description='Methods:',\n",
    "    disabled=False,\n",
    ")\n",
    "    \n",
    "\n",
    "interact(interact_results,\n",
    "         method=widget_methods,\n",
    "         metric=df['metric name'].unique(),\n",
    "         base_classifier=['ALL']+list(df['base_classifier'].unique()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observações\n",
    "\n",
    "-  Agora, todos os tripletnet iniciais são iguais. (Mesmo desempenho na primeira iteração)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['metric name']=='f1_macro'\n",
    "mask &= df['classifier name'].str.split(' ').str[0]=='tripletnet'\n",
    "mask &= df['classifier name'].str.contains('RF')\n",
    "mask &= df['train size']<=200\n",
    "\n",
    "df.loc[526,'value']=0.71\n",
    "# display(df[mask])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_research",
   "language": "python",
   "name": "env_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
